### 소개
* ML과 DL 시스템 모두 모델의 결정이 어떻게 이루어지는 지에 대해 알 수 없다는 블랙박스 문제가 존재함
* 이로인해 의료 종사자와 같이 치료 방법을 결정하기 위한 이유가 필요한 사용자에게는 AI에 대한 수용이 상대적으로 낮았음
* 본 논문에서는 제안된 모델에 XAI를 통합하려고 시도한 연구들을 검토할 것임
* 다양한 데이터셋 유형(EHR`(심전도)`, 의료 이미지, 유전 등)에 대해 어떤 XAI 기술이 더 적합하거나 널리 제안되는지 판단할 것임

### 데이터 수집 전략
* 조건에 부합한 논문을 찾기 위해 저널 데이터베이스를 이용해 1,194개의 논문을 찾음
* 연구에는 22년 3월까지의 논문들까지 포함되어 있음
* 중복 논문, 컨퍼런스 페이퍼, 연관없는 논문들을 제외시킨 후 [저널 사분위수](https://www.scimagojr.com/journalrank.php)에서 Q1을 제외한 나머지 논문들을 제거한 결과 총 99개의 논문이 선정되었음

### 결과 및 논의
* 가장 널리 사용되는 XAI 기법은 SHAP, LIME, GradCAM이었음![[Pasted image 20240504135100.png]]
#### SHAP
* SHAP 방법은 다양한 사례(중환자실 환자의 다양한 질병에 대한 사망률, 병원 입원 또는 재입원, 부작용 예측 등)에서 사용되었음
* SHAP 방법은 오랜 명성이 없음에도 불구하고 ECG, 심전도와 같은 신호뿐만 아니라 이미지와 같은 고차원 데이터를 설명하는 데에도 사용되었음
* SHAP은 LIME보다 결과를 더 쉽게 해석할 수 있기 때문에 중요한 특징을 식별할 때 사용됨

#### Local Interpretable Model-agnostic Explanations (LIME)
* SHAP과 마찬가지로 가장 중요하다고 판단되는 피처를 예측하지만, SHAP과 달리 게임 이론을 기반하는 것이 아닌 직접적으로 모델의 입력에 따른 결과가 어떻게 달라지는지를 중점으로 관찰함
* 또한, SHAP은 전체 데이터셋을 설명하는데 사용되는데 반해, LIME은 데이터 세트의 단일 샘플에 대해 설명할 수 있음
	* 즉, 모델 학습 후 학습에 포함되지 않은 샘플에 대한 모델 예측을 설명하는 데 사용됨
* 각 피처에 대한 개별 기여 확률을 제공함

#### Case-based reasoning(CBR)
* SHAP과 유사한 XAI 방법으로 모델 예측에 가장 중요한 피처를 나열함
* 예측 결과에 대한 설명을 찾기 위해 훈련이 필요하지 않기 때문에, lazy learners라고도 부름
* 분류할 새로운 샘플이 들어오면 비슷한 특성를 가진 주변의 샘플들을 사용하여 예측을 함
* 하지만 만약 너무 많은 데이터셋을 가지고 있다면 성능이 하락될 수 있다는 단점이 존재함

### 정리
![[Pasted image 20240504142056.png]]
* 정형화된 데이터셋에서 가장 널리 사용한 XAI 기법은 SHAP이었음